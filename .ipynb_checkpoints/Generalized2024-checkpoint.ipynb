{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9146e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib ipympl \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import boxcox\n",
    "from scipy.stats import yeojohnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a95b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all data into dataframe\n",
    "def load_data(path, file_names, aliases):\n",
    "    dates = {}\n",
    "    for data_set_idx in range(len(data_files)):\n",
    "        cur_alias = aliases[data_set_idx]\n",
    "        with open(path + data_files[data_set_idx] + '.csv', newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "            spamreader.__next__()\n",
    "            for row in spamreader:\n",
    "                try:\n",
    "                    cur_date = datetime.datetime.strptime(row[0], '%m/%d/%Y')\n",
    "\n",
    "                except Exception as e: \n",
    "                   continue\n",
    "                if not cur_date in dates:\n",
    "                    dates[cur_date] = {}\n",
    "#                     # need to generalize here\n",
    "#                 if data_set_idx == 0 or data_set_idx == 2:\n",
    "#                     dates[cur_date][cur_alias] = float(row[4])\n",
    "#                 elif data_set_idx == 1 or data_set_idx == 3 or data_set_idx == 4 or data_set_idx == 5:\n",
    "                try:\n",
    "                    dates[cur_date][cur_alias] = float(row[1])\n",
    "                except:\n",
    "                    print(row[1])\n",
    "                    print(cur_alias)\n",
    "                    print(row)\n",
    "                    \n",
    "\n",
    "    df = pd.DataFrame.from_dict(dates, orient='index')\n",
    "    # df.columns = aliases\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns = {'index':'Date'})\n",
    "    df = df.sort_values('Date')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1191f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not_null = df.query(baseline_asset + \".notnull()\")\n",
    "# not_null.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9cc06b2-3eea-4c50-990a-43c93913f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_div_data(asset_list, file_list):\n",
    "    div_data = {}\n",
    "    for asset, file_path in zip(asset_list, file_list):\n",
    "        # Initialize data structure for the asset\n",
    "        div_data[asset] = {\"payment_date\": set(), \"ex_date\": set(), \"amount\": {}}\n",
    "        \n",
    "        # Read CSV file into DataFrame\n",
    "        if file_path != None:\n",
    "            df = pd.read_csv(file_path, delimiter=',', header=0)\n",
    "            \n",
    "            # Iterate over rows in the DataFrame\n",
    "            for index, row in df.iterrows():\n",
    "                # Extract relevant data\n",
    "                ex_date = row[\"Ex/EFF Date\"]\n",
    "                cash_amount = row[\"Cash Amount\"]\n",
    "                payment_date = row[\"Payment Date\"]\n",
    "                \n",
    "                # Update div_data with extracted data\n",
    "                div_data[asset][\"ex_date\"].add(ex_date)\n",
    "                div_data[asset][\"payment_date\"].add(payment_date)\n",
    "                div_data[asset][\"amount\"][ex_date] = cash_amount\n",
    "            \n",
    "    return div_data\n",
    "\n",
    "\n",
    "def get_x_days_ret(asset, df, div_data, distance, idx):\n",
    "    start_idx = 0\n",
    "    end_idx = 0\n",
    "    if distance < 0:\n",
    "        distance = abs(distance)\n",
    "        start_idx = idx - distance\n",
    "        end_idx = idx + 1\n",
    "    else:\n",
    "        start_idx = idx\n",
    "        end_idx = idx + distance + 1\n",
    "        \n",
    "    num_shares = 1\n",
    "    dollars = 0\n",
    "    for i in range(start_idx, end_idx):\n",
    "        if df.iloc[i][\"Date\"] in div_data[\"payment_date\"]:\n",
    "            num_shares += dollars / df.iloc[i][asset]\n",
    "            dollars = 0\n",
    "        if df.iloc[i][\"Date\"] in div_data[\"ex_date\"]:\n",
    "            dollars += div_data[\"amount\"][df.iloc[i][\"Date\"]] * num_shares\n",
    "    final_val = num_shares * df.iloc[end_idx - 1][asset] + dollars\n",
    "    start_val = df.iloc[start_idx][asset]\n",
    "    return (final_val - start_val) / start_val\n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "def add_correlaries_div(cor_assets, cor_days_out, pred_distance, df, assets, div_data):\n",
    "    # stores percent changes from past x days \n",
    "    cors = [[] for i in range(len(cor_assets))]\n",
    "    # stores percent changes for x future days for each asset\n",
    "    futs = {}\n",
    "    for a in assets:\n",
    "        futs[a] = []\n",
    "    \n",
    "    # iterate through all data points\n",
    "    for idx, row in df.iterrows():\n",
    "        # past data points\n",
    "        for alias_idx, (asset, days_out) in enumerate(zip(cor_assets, cor_days_out)):\n",
    "            if idx > days_out: # check for enough data\n",
    "                # get percent change\n",
    "                time_period_change = get_x_days_ret(asset, df, div_data[asset], -days_out, idx)  \n",
    "                cors[alias_idx].append(time_period_change)\n",
    "            else:\n",
    "                cors[alias_idx].append(None)\n",
    "        \n",
    "        #future data\n",
    "        for asset in assets:\n",
    "            cur_price = row[asset]\n",
    "            if idx + pred_distance < df.shape[0] and not pd.isna(cur_price) and not pd.isna(df.iloc[idx + pred_distance][asset]):\n",
    "                time_period_change = get_x_days_ret(asset, df, div_data[asset], pred_distance, idx)  \n",
    "                futs[asset].append(time_period_change) \n",
    "            else:\n",
    "                futs[asset].append(None)\n",
    "    # input into data frame\n",
    "    for idx, (asset, days_out) in enumerate(zip(cor_assets, cor_days_out)):\n",
    "        name = asset + \"_\" + str(days_out) + \"_dys\"\n",
    "        df.insert(df.shape[1], name, cors[idx], True)\n",
    "    \n",
    "    for asset in futs.keys():\n",
    "        name = asset + \"_fut_\" + str(pred_distance) + \"dys\"\n",
    "        df.insert(df.shape[1], name, futs[asset], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e04a59e-595b-4dfb-b979-b9b6adcd56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_data = load_div_data([\"re\"], [\"IYRDividends.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cca94d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds correlation metrix to dataframe\n",
    "def add_correlaries(cor_assets, cor_days_out, pred_distance, df, assets):\n",
    "    # stores percent changes from past x days \n",
    "    cors = [[] for i in range(len(cor_assets))]\n",
    "    # stores percent changes for x future days for each asset\n",
    "    futs = {}\n",
    "    for a in assets:\n",
    "        futs[a] = []\n",
    "    \n",
    "    # iterate through all data points\n",
    "    for idx, row in df.iterrows():\n",
    "        # past data points\n",
    "        for alias_idx, (asset, days_out) in enumerate(zip(cor_assets, cor_days_out)):\n",
    "            cur_price = row[asset]\n",
    "            if idx > days_out: # check for enough data\n",
    "                # get percent change\n",
    "                last_time_period = df.loc[idx - days_out - 1].at[asset]\n",
    "                time_period_change = (cur_price - last_time_period)/last_time_period\n",
    "                cors[alias_idx].append(time_period_change)           \n",
    "            else:\n",
    "                cors[alias_idx].append(None)\n",
    "        \n",
    "        #future data\n",
    "        for asset in assets:\n",
    "            cur_price = row[asset]\n",
    "            if idx + pred_distance < df.shape[0] and not pd.isna(cur_price) and not pd.isna(df.iloc[idx + pred_distance].at[asset]):\n",
    "                fut_val = df.iloc[idx + pred_distance].at[asset]\n",
    "                time_period_change = (fut_val - cur_price)/cur_price  \n",
    "                futs[asset].append(time_period_change) \n",
    "            else:\n",
    "                futs[asset].append(None)\n",
    "    # input into data frame\n",
    "    for idx, (asset, days_out) in enumerate(zip(cor_assets, cor_days_out)):\n",
    "        name = asset + \"_\" + str(days_out) + \"_dys\"\n",
    "        df.insert(df.shape[1], name, cors[idx], True)\n",
    "    \n",
    "    for asset in futs.keys():\n",
    "        name = asset + \"_fut_\" + str(pred_distance) + \"dys\"\n",
    "        df.insert(df.shape[1], name, futs[asset], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "302592d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pred_differences(pred_distance, baseline_asset, assets, df):\n",
    "    for idx, asset in enumerate(assets):\n",
    "#       for idx2, asset2 in enumerate(assets[idx + 1: ]): if you want all differences\n",
    "        if asset != baseline_asset:\n",
    "            change_asset = df[asset + \"_fut_\" + str(pred_distance) + \"dys\"]\n",
    "            change_baseline = df[baseline_asset + \"_fut_\" + str(pred_distance) + \"dys\"]\n",
    "            diff = change_asset - change_baseline \n",
    "            df.insert(df.shape[1], asset + \"_\" + baseline_asset + \"_\" + str(pred_distance) + \"dys_diff\", diff, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c42dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_null.iloc[5700:5750,[0, 7,8, 9, 10,11,12,13,14,15,16,17,18,19,20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b6777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_null.iloc[-160:,0: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a440989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not_null.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6a6e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use sklearn.preprocessing.PowerTransformer instead\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# column_name = 'sp_20_dys'\n",
    "# column = not_null[column_name] \n",
    "# column = column[~np.isnan(column)]\n",
    "# print(column)\n",
    "# # column += np.array([1 for i in range(len(column))])\n",
    "# # print(column)\n",
    "# plt.figure()\n",
    "# plt.hist(column , color = 'red', bins = 500, density=True)\n",
    "# mean = np.mean(column)\n",
    "# std = np.std(column)\n",
    "# print(mean)\n",
    "# print(std)\n",
    "# x_axis = np.arange(-.3, .3, 0.01)\n",
    "\n",
    "# plt.plot(x_axis, norm.pdf(x_axis, mean, std))\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(yeojohnson(column)[0] , color = 'red', bins = 500, density=True)\n",
    "# mean = np.mean(yeojohnson(column)[0])\n",
    "# std = np.std(yeojohnson(column)[0])\n",
    "# print(mean)\n",
    "# print(std)\n",
    "# x_axis = np.arange(-.3, .3, 0.01)\n",
    "\n",
    "# plt.plot(x_axis, norm.pdf(x_axis, mean, std))\n",
    "# # plt.hist(np.log(sp_not_null[column_name] + np.array([1 for i in range(len(sp_not_null[column_name]))])) , color = 'red', bins = 500, density=True)\n",
    "# # mean = np.mean(np.log(sp_not_null[column_name] + np.array([1 for i in range(len(sp_not_null[column_name]))])))\n",
    "# # std = np.std(np.log(sp_not_null[column_name] + np.array([1 for i in range(len(sp_not_null[column_name]))])))\n",
    "\n",
    "\n",
    "\n",
    "# # column += np.array([1 for i in range(len(column))])\n",
    "# # column = np.log(column)\n",
    "# # plt.figure()\n",
    "# # plt.hist(yeojohnson(column)[0] , color = 'red', bins = 500, density=True)\n",
    "# # mean = np.mean(yeojohnson(column)[0])\n",
    "# # std = np.std(yeojohnson(column)[0])\n",
    "# # print(mean)\n",
    "# # print(std)\n",
    "# # x_axis = np.arange(-.3, .3, 0.01)\n",
    "\n",
    "# plt.plot(x_axis, norm.pdf(x_axis, mean, std))\n",
    "# # plt.hist(sp_not_null['sp_fut_2wks'], color = 'red', bins = 500)\n",
    "# # plt.hist(sp_not_null['re_fut_2wks'], color = 'green', bins = 500, alpha = .5,)\n",
    "# # plt.hist(sp_not_null['bnd_fut_2wks'], color = 'blue', bins = 500, alpha = .5,)\n",
    "# # plt.hist(sp_not_null['gld_fut_2wks'], color = 'yellow', bins = 500, alpha = .5,)\n",
    "# # plt.hist(sp_not_null['eu_fut_2wks'], color = 'green', bins = 500, alpha = .5,)\n",
    "# # plt.hist(sp_not_null['jp_fut_2wks'], color = 'blue', bins = 500, alpha = .5,)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13a2a30e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(projection = '3d')\n",
    "\n",
    "# ax.scatter(not_null[\"sp_last_month\"], not_null[\"re_last_month\"], not_null[\"re_sp_2wk_diff\"])\n",
    "# ax.set_xlabel('sp_last_month')\n",
    "# ax.set_ylabel('re_last_month')\n",
    "# ax.set_zlabel('re_sp_2wk_diff')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c4b85e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rvs(baseline, df, aliases, pred_distance, print_mats=False):\n",
    "    rvs = {}\n",
    "    \n",
    "    valid_cols = []\n",
    "    for col in df.columns:\n",
    "        if not col in aliases and col != \"Date\" and not \"diff\" in col and not \"fut\" in col:\n",
    "            valid_cols.append(col)\n",
    "    valid_cols.append(None)\n",
    "    \n",
    "    for asset in aliases:\n",
    "        if asset != baseline:\n",
    "            valid_cols[-1] = (asset + \"_\" + baseline + \"_\" + str(pred_distance) + \"dys_diff\")\n",
    "\n",
    "            cov_mat = df[valid_cols]\n",
    "            cov_matrix = pd.DataFrame.cov(cov_mat)\n",
    "            cov_mat = cov_mat.cov()\n",
    "            cov_mat = cov_mat.to_numpy()\n",
    "            if print_mats:\n",
    "                print(asset)\n",
    "                print(cov_matrix)\n",
    "\n",
    "\n",
    "            # means of values\n",
    "            means = []\n",
    "            for col in valid_cols:\n",
    "                means.append(np.mean(df[col]))\n",
    "            if print_mats:\n",
    "                print(means)\n",
    "\n",
    "            rv = multivariate_normal(mean=means, cov=cov_mat, allow_singular=True)\n",
    "            rvs[asset] = rv\n",
    "    return rvs\n",
    "        \n",
    "\n",
    "\n",
    "def predict(asset, baseline, rv, inputs, get_plots=False, do_print=False, get_50_pt = False):\n",
    "    START = -.22\n",
    "    STOP = .22\n",
    "    INCREMENT = .00005\n",
    "\n",
    "    probs = []\n",
    "   \n",
    "    x = np.arange(START, STOP, INCREMENT)\n",
    "    inputs.append(None)\n",
    "    for val in x:\n",
    "        # make an array with all the current values\n",
    "        # insert past month performance\n",
    "        #\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", future difference\n",
    "        inputs[-1] = val\n",
    "        probs.append(rv.pdf(inputs))\n",
    "\n",
    "\n",
    "    cdf = []\n",
    "    for idx in range(x.size - 1):\n",
    "        cur_prob = probs[idx]\n",
    "        next_prob = probs[idx + 1]\n",
    "        rieman_sum = min(cur_prob, next_prob) * INCREMENT\n",
    "        rieman_sum += max(cur_prob, next_prob) - min(cur_prob, next_prob) * INCREMENT / 2\n",
    "        if len(cdf) > 0:\n",
    "            cdf.append(rieman_sum + cdf[-1])\n",
    "        else:\n",
    "            cdf.append(rieman_sum)\n",
    "                                 \n",
    "    if get_plots:\n",
    "        fig1 = plt.figure()\n",
    "        ax = fig1.add_subplot(111)\n",
    "        plt.title(\"pdf\")\n",
    "        plt.xlabel(\"difference between performance of \" + asset + \" and \" + baseline)\n",
    "        plt.ylabel(\"probability\")\n",
    "        ax.plot(x, probs/cdf[-1])\n",
    "        plt.show()\n",
    "\n",
    "    for idx in range(len(cdf)):\n",
    "        cdf[idx] /= cdf[-1]\n",
    "\n",
    "    if get_plots:\n",
    "        fig2 = plt.figure()\n",
    "        ax = fig2.add_subplot(111)\n",
    "        plt.title(\"cdf\")\n",
    "        plt.xlabel(\"difference between performance of \" + asset + \" and \" + baseline)\n",
    "        plt.ylabel(\"probability\")\n",
    "        ax.plot(x[:-1], cdf)\n",
    "        plt.show() \n",
    "        \n",
    "    if get_50_pt:\n",
    "        # find 50% point\n",
    "        cur_prob = 0\n",
    "        idx = 0\n",
    "        while(cur_prob < .5):\n",
    "            cur_prob = cdf[idx]\n",
    "            idx += 1\n",
    "        fiftyfiftypt = x[idx]\n",
    "        if do_print:\n",
    "            print(\"50 50 change to be above or below\")\n",
    "            print(x[idx])\n",
    "\n",
    "\n",
    "    #find expected value\n",
    "    expected_value = 0\n",
    "    for idx in range(len(cdf)):\n",
    "        if idx == 0:\n",
    "            expected_value += cdf[idx] * x[idx]\n",
    "        else:\n",
    "            cur_prob = cdf[idx - 1]\n",
    "            next_prob = cdf[idx]\n",
    "            actual_prob = next_prob - cur_prob\n",
    "            expected_value += actual_prob * x[idx]\n",
    "                                 \n",
    "    if do_print:\n",
    "        print(\"Expected Value\")\n",
    "        print(expected_value)\n",
    "                                 \n",
    "    if get_50_pt:\n",
    "        return fiftyfiftypt, expected_value\n",
    "    else:\n",
    "        return expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af092e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preds(assets, baseline, pred_distance, df_test, df_train):\n",
    "    rvs = get_rvs(baseline, df_train, assets, pred_distance)\n",
    "    preds = {}\n",
    "    actuals = {}\n",
    "    for asset in assets:\n",
    "        if asset != baseline:\n",
    "            preds[asset] = []\n",
    "            actuals[asset] = []\n",
    "    \n",
    "    pred_columns = []\n",
    "    for col_idx, col in enumerate(df.columns):\n",
    "        if not col in aliases and col != \"Date\" and not \"diff\" in col and not \"fut\" in col:\n",
    "            pred_columns.append(col_idx)\n",
    "            \n",
    "            \n",
    "    print('start')\n",
    "    for idx, row in df_test.iterrows():\n",
    "        for asset in assets:\n",
    "            if asset != baseline:\n",
    "#                 print(asset)\n",
    "                col_name = asset + \"_\" + baseline  + \"_\" + str(pred_distance) + \"dys_diff\"\n",
    "                actual = row[col_name]\n",
    "                actuals[asset].append(actual)\n",
    "#                 print(actual)\n",
    "                columns = []\n",
    "                pred_input = df_test.iloc[idx, pred_columns]\n",
    "                if not pred_input.isnull().any():\n",
    "                    prediction = predict(asset, baseline, rvs[asset], pred_input.tolist(), get_plots=False)\n",
    "                    preds[asset].append(prediction)\n",
    "                    # print(prediction)\n",
    "                else:\n",
    "                    preds[asset].append(None)\n",
    "#                     print(None)\n",
    "#                 print(\"---------\")\n",
    "        if idx % 10== 0:\n",
    "            print(idx)\n",
    "\n",
    "    return preds, actuals            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9560539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs here\n",
    "\n",
    "# path = 'C:\\\\Users\\\\plant\\\\\n",
    "path = ''\n",
    "\n",
    "baseline_asset = 'sp'\n",
    "\n",
    "file_SP = 'SPY'  \n",
    "div_SP = 'SPYDividend'\n",
    "file_RE = 'IYR'\n",
    "div_RE = 'IYRDividend'\n",
    "file_BND = 'isharesBondIndexSince2003'\n",
    "div_BND = 'USAggBondDividend'\n",
    "file_EU = 'USD_EURHistoricalData'\n",
    "div_EU = None\n",
    "file_JPY = 'USD_JPYHistoricalData'\n",
    "div_JP = None\n",
    "file_GLD = 'GoldFuturesHistoricalData'\n",
    "div_GLD = None\n",
    "file_MID = 'IJH'\n",
    "div_MID = 'IJHDividend'\n",
    "file_SML = 'IJR'\n",
    "div_SML = 'IJRDividend'\n",
    "file_RUT = 'IWM'\n",
    "div_RUT = 'IWMDividend'\n",
    "file_EST = 'EZU'\n",
    "div_EST = 'EZUDividend'\n",
    "file_EMR = 'EEM'\n",
    "div_EMR = 'EEMDividend'\n",
    "file_JST = 'EWJ'\n",
    "div_JST = 'EWJDividend'\n",
    "\n",
    "# data_files = [file_name_SP, file_name_RE, file_name_BND, file_name_EU, file_name_JPY, file_name_GOLD, file_name_RUT]\n",
    "# aliases = [\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", 'rut']\n",
    "\n",
    "# # input correlaries\n",
    "# cor_assets = [\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", 'rut', \"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", 'rut', \"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", 'rut', \"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", 'rut']\n",
    "# cor_days_out = [20, 20, 20, 20, 20, 20, 20, 10, 10, 10, 10, 10, 10, 10, 252, 252, 252, 252, 252, 252, 252, 60, 60, 60, 60, 60, 60, 60]\n",
    "# pred_distance = 10\n",
    "# assets = [\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", 'rut']\n",
    "\n",
    "\n",
    "data_files = [file_SP, file_RE, file_BND, file_EU, file_JP, file_GLD, file_MID, file_SML, file_RUT, file_EST, file_EMR, file_JST]\n",
    "div_files = [div_SP, div_RE, div_BND, div_EU, div_JP, div_GLD, div_MID, div_SML, div_RUT, div_EST, div_EMR, div_JST]\n",
    "aliases = [\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", \"mid\", \"sml\", \"rut\", \"est\", \"emr\", \"jst\"]\n",
    "\n",
    "# input correlaries\n",
    "# cor_assets = ['sp', \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", \"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", \"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\",  \"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\"]\n",
    "# cor_days_out = [20,   20,    20,   20,   20,    20,   10,   10,   10, 10,   10,   10,   252,  252, 252, 252,  252,   252,    60,   60,    60,    60,    60,   60]\n",
    "cor_assets = [\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", \"mid\", \"sml\", \"rut\", \"est\", \"emr\", \"jst\"]\n",
    "cor_days_out = [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
    "pred_distance = 10\n",
    "assets = [ [\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\", \"mid\", \"sml\", \"rut\", \"est\", \"emr\", \"jst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3920ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(path, data_files, aliases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e92f941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>sp</th>\n",
       "      <th>gld</th>\n",
       "      <th>eu</th>\n",
       "      <th>jp</th>\n",
       "      <th>re</th>\n",
       "      <th>bnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>359.690002</td>\n",
       "      <td>404.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date          sp    gld  eu  jp  re  bnd\n",
       "0 1990-01-02  359.690002  404.5 NaN NaN NaN  NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1162178c-2a28-4ad3-a0f1-2eb5f5a107ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.query(baseline_asset + \".notnull()\")\n",
    "df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06653bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_correlaries(cor_assets, cor_days_out, pred_distance, df, assets)\n",
    "div_data = load_div_data([\"sp\", \"re\", \"bnd\", \"eu\", \"jp\", \"gld\"], [None, \"IYRDividends.csv\", None, None, None, None])\n",
    "add_correlaries_div(cor_assets, cor_days_out, pred_distance, df, assets, div_data)\n",
    "add_pred_differences(pred_distance, baseline_asset, assets, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfa994e-5cbd-4e5e-bbf0-d60e48ef2d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab83581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6e696b-568c-40b8-a068-7cd2cbf89b8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb314bac-7252-40ae-af70-ecdbcef4a3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[8060: 8061, [0, 1, 2, 3, 4, 5, 6, 7, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3fc03-cda9-4a1e-b355-9559dbdcd670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[(df['Date'] >= '2009-01-01') & (df['Date'] <= '2009-12-30')]\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_train = df[(df['Date'] < '2009-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e27e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds, actuals = test_preds(aliases, baseline_asset, pred_distance, df_test, df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354470e-9d90-4b02-bb13-300c7855f4c9",
   "metadata": {},
   "source": [
    "# import pickle \n",
    "\n",
    "with open('preds.pkl', 'wb') as f:\n",
    "    pickle.dump(preds, f)\n",
    "\n",
    "with open('actuals.pkl', 'wb') as f:\n",
    "    pickle.dump(actuals, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857c67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"preds.pkl\",'rb') as f:\n",
    "    preds = pickle.load(f)\n",
    "    \n",
    "with open(\"actuals.pkl\",'rb') as f:\n",
    "    actuals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_cor_neg = 0\n",
    "sign_cor_pos = 0\n",
    "incor_actual_neg = 0\n",
    "incor_actual_pos = 0\n",
    "total_diff = 0\n",
    "total_count = 0\n",
    "total_correct = 0\n",
    "\n",
    "for pred, actual in zip(preds['gld'], actuals['gld']):\n",
    "    if pred != None and not pd.isna(actual):\n",
    "        if pred < 0 and actual < 0:\n",
    "            sign_cor_neg += 1\n",
    "            total_correct += 1\n",
    "        elif pred > 0 and actual > 0:\n",
    "            sign_cor_pos += 1\n",
    "            total_correct += 1\n",
    "        elif actual < 0:\n",
    "            incor_actual_neg += 1\n",
    "        else:\n",
    "            incor_actual_pos +=1\n",
    "        total_count += 1\n",
    "        total_diff += abs(pred - actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d548df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pred neg actual neg\")\n",
    "print(sign_cor_neg)\n",
    "print(\"pred pos actual pos\")\n",
    "print(sign_cor_pos)\n",
    "print(\"pred pos actual neg\")\n",
    "print(incor_actual_neg) \n",
    "print(\"pred neg actual pos\")\n",
    "print(incor_actual_pos )\n",
    "\n",
    "print(\"-----\")\n",
    "print(\"total neg\")\n",
    "print(sign_cor_neg + incor_actual_neg)\n",
    "print(\"total pos\")\n",
    "print(sign_cor_pos + incor_actual_pos)\n",
    "print(\"----\")\n",
    "print(\"ave diff\")\n",
    "print(total_diff/total_count)\n",
    "print(\"percent correct\")\n",
    "print(total_correct/total_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb11bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 1\n",
    "period_counts = 0\n",
    "\n",
    "count = 0\n",
    "\n",
    "test_asset = 're'\n",
    "offset = 2\n",
    "\n",
    "for date, pred, actual in zip(df_test[\"Date\"][offset:], preds[test_asset][offset:], actuals[test_asset][offset:]):\n",
    "    if pred != None and not pd.isna(actual):\n",
    "        if count == 10:\n",
    "            # if pred > .01:\n",
    "            if pred > 0:\n",
    "                total *= (1 + 10 * pred * actual)\n",
    "                print(\"long: \" + str(date) + \": \" + str(total))\n",
    "            # if pred < -.01:\n",
    "            if pred < 0:\n",
    "                total *= (1 + 10  * abs(pred) * -(actual))\n",
    "                print(\"shorted: \" + str(date) + \": \" + str(total))\n",
    "            period_counts += 1\n",
    "    #         else:\n",
    "    #             total *= (1 + actual)\n",
    "            \n",
    "            count = 0\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "print(test_asset)\n",
    "print(total)\n",
    "print(period_counts)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8df5fcda-d45d-459f-9c16-bd33b0ca734f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543b5e8-aec8-454f-839d-895491f909e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef69b8-cefd-4f3f-b633-63ee8f55e3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703d1804-89b2-4bbc-90d7-952921840070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499f26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
